{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "063d3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries that is needed for the implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# for data visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "#Importing necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from copy import copy,deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40ce270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "089f7408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "317b2775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     Work experience         Education   Company size  Amount  \\\n",
       "0            1_to_3  bachelors_degree     100_to_500  120000   \n",
       "1            1_to_3  bachelors_degree     100_to_500   65000   \n",
       "2            1_to_3  bachelors_degree     100_to_500  230000   \n",
       "3            7_to_9  bachelors_degree     100_to_500  260000   \n",
       "4            1_to_3  bachelors_degree       20_to_50  120000   \n",
       "..              ...               ...            ...     ...   \n",
       "519          0_to_1  bachelors_degree     100_to_500  210000   \n",
       "520          4_to_6  bachelors_degree  more_than_500  220000   \n",
       "521          4_to_6  bachelors_degree  more_than_500  240000   \n",
       "522          4_to_6  bachelors_degree  more_than_500  260000   \n",
       "523          4_to_6  bachelors_degree  more_than_500  310000   \n",
       "\n",
       "                     Designation  \n",
       "0       senior_software_engineer  \n",
       "1    associate_software_engineer  \n",
       "2              software_engineer  \n",
       "3          senior_ui_ux_engineer  \n",
       "4              software_engineer  \n",
       "..                           ...  \n",
       "519               technical_lead  \n",
       "520     associate_technical_lead  \n",
       "521     senior_software_engineer  \n",
       "522                 architecture  \n",
       "523                 architecture  \n",
       "\n",
       "[524 rows x 5 columns]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd2ae9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Work experience    object\n",
       "Education          object\n",
       "Company size       object\n",
       "Amount              int64\n",
       "Designation        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bebe03eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#droping rows with No values\n",
    "data = data.dropna(axis=0)\n",
    "data_string = deepcopy(data) \n",
    "data.shape\n",
    "data_string.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b17abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work experience\n",
      "Education\n",
      "Company size\n",
      "Amount\n",
      "Designation\n",
      "   Work experience  Education  Company size  Amount  Designation\n",
      "0                3          0             0      29           48\n",
      "1                3          0             0      13           12\n",
      "2                3          0             0      70           54\n",
      "3                5          0             0      79           52\n",
      "4                3          0             2      29           54\n",
      "  Work experience         Education Company size  Amount  \\\n",
      "0          1_to_3  bachelors_degree   100_to_500  120000   \n",
      "1          1_to_3  bachelors_degree   100_to_500   65000   \n",
      "2          1_to_3  bachelors_degree   100_to_500  230000   \n",
      "3          7_to_9  bachelors_degree   100_to_500  260000   \n",
      "4          1_to_3  bachelors_degree     20_to_50  120000   \n",
      "\n",
      "                   Designation  \n",
      "0     senior_software_engineer  \n",
      "1  associate_software_engineer  \n",
      "2            software_engineer  \n",
      "3        senior_ui_ux_engineer  \n",
      "4            software_engineer  \n"
     ]
    }
   ],
   "source": [
    "#Assigning integers to categorical values\n",
    "number = preprocessing.LabelEncoder()\n",
    "\n",
    "for feature in data.columns :\n",
    "        #Checking whether the column type is and integer\n",
    "        if type (feature) is not int : \n",
    "            data[feature] = number.fit_transform(data[feature])\n",
    "            print(feature)\n",
    "print(data.head())\n",
    "print(data_string.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31a51cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing dependent and independent variables\n",
    "independent = 'Amount'\n",
    "features = list(data.columns)\n",
    "\n",
    "features.remove(independent)\n",
    "\n",
    "X = data[features]\n",
    "y = data[independent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b639776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477    23\n",
       "314    72\n",
       "304    96\n",
       "521    74\n",
       "180    96\n",
       "Name: Amount, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3212b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Function to calculate Accuracy\n",
    "# def get_accuracy_random(max_leaf_nodes, train_X, val_X, train_y, val_y,criterion='gini'):\n",
    "#     model = RandomForestClassifier(max_leaf_nodes=max_leaf_nodes, random_state=1,criterion=criterion)\n",
    "#     model.fit(train_X, train_y)\n",
    "#     preds_val = model.predict(val_X)\n",
    "#     mae = accuracy_score(val_y, preds_val)\n",
    "#     return(mae)\n",
    "\n",
    "def get_accuracy_random(train_X, val_X, train_y, val_y,criterion='gini'):\n",
    "    model = RandomForestClassifier(random_state=1,criterion=criterion)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = accuracy_score(val_y, preds_val)\n",
    "    return(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b054fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007633587786259542\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy_random(train_X, test_X, train_y, test_y,'entropy'))\n",
    "test_X,test_Y = train_X,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7c123ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score : 0.5648854961832062\n"
     ]
    }
   ],
   "source": [
    "#Creating the model to get the best accuracy\n",
    "rf_model = RandomForestClassifier(random_state=1,criterion='entropy')\n",
    "\n",
    "#Training the model\n",
    "rf_model.fit(train_X,train_y)\n",
    "\n",
    "# Predicting\n",
    "pred = rf_model.predict(test_X)\n",
    "\n",
    "#Final Score\n",
    "print(f'Final Score : {accuracy_score(test_Y,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e06e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:       Work experience  Education  Company size  Designation\n",
      "477                3          0             0           54\n",
      "314                3          0             5           48\n",
      "Y:  477    23\n",
      "314    72\n",
      "Name: Amount, dtype: int64\n",
      "[49 85 96 23 96]\n",
      "[175000, 275000, 300000, 100000, 300000]\n"
     ]
    }
   ],
   "source": [
    "output = rf_model.predict(train_X.head())\n",
    "\n",
    "print(\"X: \",train_X.head(2))\n",
    "print(\"Y: \", train_y.head(2))\n",
    "\n",
    "print(output)\n",
    "color = []\n",
    "for m in output:\n",
    "  for i in range(len(data['Amount'])):\n",
    "    if m== data['Amount'][i] :\n",
    "      color.append(data_string['Amount'][i])\n",
    "      break \n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44a18f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Defining Function to calculate Accuracy\n",
    "# def get_accuracy_logistic(train_X, val_X, train_y, val_y):\n",
    "#     scaler = StandardScaler()\n",
    "#     train_X_scaled = scaler.fit_transform(train_X)\n",
    "#     val_X_scaled = scaler.transform(val_X)\n",
    "\n",
    "# # create and fit the model\n",
    "#     model = LogisticRegression(random_state=25, solver='saga', max_iter=5000)\n",
    "#     model.fit(train_X_scaled, train_y)\n",
    "\n",
    "# # make predictions and calculate accuracy\n",
    "#     preds_val = model.predict(val_X_scaled)\n",
    "#     accuracy = accuracy_score(val_y, preds_val)\n",
    "#     return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fc296bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# def get_accuracy_svd(train_X, val_X, train_y, val_y, n_components=100):\n",
    "#     # create SVD pipeline\n",
    "#     svd = TruncatedSVD(n_components=n_components, random_state=25)\n",
    "#     scaler = StandardScaler()\n",
    "#     classifier = GaussianNB()\n",
    "#     pipeline = make_pipeline(svd, scaler, classifier)\n",
    "\n",
    "#     # fit the model\n",
    "#     pipeline.fit(train_X, train_y)\n",
    "\n",
    "#     # make predictions and calculate accuracy\n",
    "#     preds_val = pipeline.predict(val_X)\n",
    "#     accuracy = accuracy_score(val_y, preds_val)\n",
    "#     return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "108ceeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# def get_accuracy_naive_bayes(train_X, val_X, train_y, val_y):\n",
    "#     # create scaler and fit_transform the data\n",
    "#     scaler = StandardScaler()\n",
    "#     train_X_scaled = scaler.fit_transform(train_X)\n",
    "#     val_X_scaled = scaler.transform(val_X)\n",
    "\n",
    "#     # create and fit the model\n",
    "#     model = GaussianNB()\n",
    "#     model.fit(train_X_scaled, train_y)\n",
    "\n",
    "#     # make predictions and calculate accuracy\n",
    "#     preds_val = model.predict(val_X_scaled)\n",
    "#     accuracy = accuracy_score(val_y, preds_val)\n",
    "#     return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f96b2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Naiva: \", get_accuracy_naive_bayes(train_X, test_X, train_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0f8d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"SVD: \", get_accuracy_svd(train_X, test_X, train_y, test_y,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b895af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Logistic: \", get_accuracy_logistic(train_X, test_X, train_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14d6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dabe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0b5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d1a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "140f9848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Work experience    0\n",
       "Education          0\n",
       "Company size       0\n",
       "Amount             0\n",
       "Designation        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd9f10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['Work experience', 'Company size', 'Education', 'Amount','Designation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4473ccca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e6f1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17e6348f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Designation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Designation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17840\\1626593709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Preprocess job title data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Designation'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Designation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Split data into training and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Designation'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess job title data\n",
    "data['Designation'] = data['Designation'].apply(lambda x: x.lower())\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Collaborative filtering: train a linear regression model\n",
    "collab_features = pd.get_dummies(train_data[['Work experience','Company size', 'Education']])\n",
    "collab_model = LinearRegression().fit(collab_features, train_data['Amount'])\n",
    "\n",
    "# Content-based filtering: train a gradient boosting model\n",
    "vectorizer = TfidfVectorizer()\n",
    "job_title_features = vectorizer.fit_transform(train_data['Designation'])\n",
    "content_features = pd.concat([pd.get_dummies(train_data[['Work experience','Company size', 'Education']]), \n",
    "                              pd.DataFrame(job_title_features.toarray(), columns=vectorizer.get_feature_names())], \n",
    "                             axis=1)\n",
    "content_model = GradientBoostingRegressor().fit(content_features, train_data['Amount'])\n",
    "\n",
    "# Compute predicted salaries for test set\n",
    "test_collab_features = pd.get_dummies(test_data[['Work experience','Company size', 'Education']])\n",
    "test_content_features = pd.concat([pd.get_dummies(test_data[['Work experience','Company size', 'education']]), \n",
    "                                  pd.DataFrame(vectorizer.transform(test_data['Designation']).toarray(), \n",
    "                                               columns=vectorizer.get_feature_names())], \n",
    "                                 axis=1)\n",
    "test_collab_preds = collab_model.predict(test_collab_features)\n",
    "test_content_preds = content_model.predict(test_content_features)\n",
    "\n",
    "# Combine predictions with weighted average\n",
    "collab_weight = 0.7 # adjust this weight based on performance on training data\n",
    "content_weight = 0.3 # adjust this weight based on performance on training data\n",
    "test_preds = (collab_weight * test_collab_preds) + (content_weight * test_content_preds)\n",
    "\n",
    "# Evaluate performance on test set\n",
    "mse = mean_squared_error(test_data['Amount'], test_preds)\n",
    "print('MSE:', mse)\n",
    "\n",
    "# Save the models to disk\n",
    "joblib.dump(collab_model, 'collab_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "joblib.dump(content_model, 'content_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd27378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Extract relevant features from the job title data\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "job_title_features = vectorizer.fit_transform(data['Designation'])\n",
    "\n",
    "# Add other features such as experience level, location, and education\n",
    "features = pd.concat([pd.get_dummies(data['Work experience']), \n",
    "                      pd.DataFrame(job_title_features.toarray(), columns=vectorizer.get_feature_names())], \n",
    "                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b395f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, data['Amount'], test_size=0.1, random_state=1)\n",
    "\n",
    "# Initialize a Gradient Boosting Regression model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea751f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Fine-tune the hyperparameters of the model using GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 500, 1000], \n",
    "              'learning_rate': [0.1, 0.05, 0.01], \n",
    "              'max_depth': [3, 5, 7]}\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print('Best hyperparameters:', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d367f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model for deployment\n",
    "joblib.dump(model, 'salary_recommendation_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model from disk\n",
    "import joblib\n",
    "model = joblib.load('salary_recommendation_model.pkl')\n",
    "\n",
    "# Preprocess the new job title data\n",
    "new_data = pd.DataFrame({'Designation': ['software_engineer'], \n",
    "                         'Work experience': ['10_to_14'],\n",
    "                         'Amount': [0]})\n",
    "new_data['Designation'] = new_data['Designation'].apply(lambda x: x.lower())\n",
    "\n",
    "# Extract relevant features from the job title data\n",
    "job_title_features = vectorizer.transform(new_data['Designation'])\n",
    "\n",
    "# Add other features such as experience level, location, and education\n",
    "new_features = pd.concat([pd.get_dummies(new_data['Work experience']), \n",
    "                          pd.DataFrame(job_title_features.toarray(), columns=vectorizer.get_feature_names())], \n",
    "                         axis=1)\n",
    "\n",
    "# Use the trained model to make predictions on the new data\n",
    "prediction = model.predict(new_features)\n",
    "\n",
    "# Print the predicted salary\n",
    "print('Predicted salary:', prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd220bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert categorical variables to numerical values using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['Work experience', 'Education', 'Company size', 'Designation'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('Amount', axis=1)\n",
    "y = data['Amount']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared score:', r2)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c35929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Amount', axis=1)\n",
    "y = df['Amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce339be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Select the relevant features\n",
    "relevant_features = corr.index[abs(corr['Amount']) > 0.5]\n",
    "print(relevant_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the random forest regression model\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the selected features\n",
    "regressor.fit(X_train[relevant_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edac86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
